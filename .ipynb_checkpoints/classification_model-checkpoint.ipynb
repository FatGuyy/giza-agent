{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Gvwq0A6xz6yN",
        "Y3XziLxT5EF_",
        "sEY7pw06z1eJ",
        "uAMlaQvczzAB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#prerun"
      ],
      "metadata": {
        "id": "Gvwq0A6xz6yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta\n",
        "!pip install backtesting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTosz8hJHDqw",
        "outputId": "24953a52-e706-45f8-f975-11e9a4424dfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n",
            "Requirement already satisfied: backtesting in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from backtesting) (1.25.2)\n",
            "Requirement already satisfied: pandas!=0.25.0,>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from backtesting) (2.0.3)\n",
            "Requirement already satisfied: bokeh>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from backtesting) (3.3.4)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.4.0->backtesting) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.4.0->backtesting) (1.2.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.4.0->backtesting) (24.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.4.0->backtesting) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.4.0->backtesting) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.4.0->backtesting) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.4.0->backtesting) (2024.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh>=1.4.0->backtesting) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=0.25.0,>=0.25.0->backtesting) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ta\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "\n",
        "#for backtesting\n",
        "from backtesting import Backtest, Strategy\n",
        "from backtesting.lib import crossover\n",
        "import numpy as np\n",
        "\n",
        "#for plotting\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsBmeuYzz9p2",
        "outputId": "7265e587-7554-441e-e2ad-8120f006d0d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/backtesting/_plotting.py:50: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support (e.g. PyCharm, Spyder IDE). Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
            "  warnings.warn('Jupyter Notebook detected. '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#main functions"
      ],
      "metadata": {
        "id": "Y3XziLxT5EF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, file, threshold , window):\n",
        "        self.file = file\n",
        "        self.threshold = threshold\n",
        "        self.window = window\n",
        "\n",
        "    def set(self, file, period_buy, period_sell, buy_threshold, sell_threshold):\n",
        "        self.file = file\n",
        "        self.period_buy = period_buy\n",
        "        self.period_sell = period_sell\n",
        "        self.buy_threshold = buy_threshold\n",
        "        self.sell_threshold = sell_threshold\n",
        "\n",
        "    def signal_setting(self):\n",
        "        try:\n",
        "            # Load from csv if file is a string\n",
        "            if isinstance(self.file, str):\n",
        "                df = pd.read_csv(self.file)\n",
        "            # If file is already a DataFrame\n",
        "            elif isinstance(self.file, pd.DataFrame):\n",
        "                df = self.file\n",
        "            else:\n",
        "                raise TypeError(\"File should be a string or a DataFrame\")\n",
        "        except Exception as e:\n",
        "            print(\"Error loading dataset:\", e)\n",
        "            return None\n",
        "\n",
        "        # Calculate EMA 50 and EMA 200\n",
        "        df['ema_50'] = ta.trend.ema_indicator(close=df['Close'], window=50)\n",
        "        df['ema_200'] = ta.trend.ema_indicator(close=df['Close'], window=200)\n",
        "\n",
        "        # Calculate MACD\n",
        "        df['macd'] = ta.trend.macd_diff(close=df['Close'])\n",
        "\n",
        "        # Calculate RSI\n",
        "        df['rsi'] = ta.momentum.rsi(close=df['Close'], window=14)\n",
        "\n",
        "        # Calculate Stochastic Oscillator\n",
        "        df['stoch_oscillator'] = ta.momentum.stoch(close=df['Close'] , high=df[\"High\"] , low=df[\"Low\"])\n",
        "\n",
        "        # Calculate Average True Range (ATR)\n",
        "        df['atr'] = ta.volatility.average_true_range(high=df['High'], low=df['Low'], close=df['Close'])\n",
        "\n",
        "        # Calculate On-Balance Volume (OBV)\n",
        "        df['obv'] = ta.volume.on_balance_volume(close=df['Close'], volume=df['Volume'])\n",
        "\n",
        "        # Calculate Ichimoku Cloud\n",
        "        df['ichimoku_a'] = ta.trend.ichimoku_a(high=df['High'], low=df['Low'])\n",
        "\n",
        "        # Drop rows with NaN values\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        # Convert 'close' column to float\n",
        "        df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
        "\n",
        "\n",
        "\n",
        "        #calculate\n",
        "        window_size = self.window\n",
        "        min = self.threshold\n",
        "        step_size = window_size\n",
        "\n",
        "\n",
        "\n",
        "        # Divide the DataFrame into equal parts\n",
        "        num_windows = len(df) // window_size\n",
        "        windows = [df.iloc[i * window_size:(i + 1) * window_size] for i in range(num_windows)]\n",
        "\n",
        "        # Iterate over each window\n",
        "        for window in windows:\n",
        "            # Calculate highest and lowest points within the window\n",
        "            highest_point = window['Close'].max()\n",
        "            lowest_point = window['Close'].min()\n",
        "\n",
        "            # Calculate the difference between the highest and lowest points\n",
        "            diff = (highest_point - lowest_point) / lowest_point\n",
        "\n",
        "            # If the difference is greater than 0.1, mark the points as valid\n",
        "            if diff > min:\n",
        "                highest_index = window[window['Close'] == highest_point].index[0]\n",
        "                lowest_index = window[window['Close'] == lowest_point].index[0]\n",
        "\n",
        "                # Set 'sell' to 1 for the highest point and 'buy' to 1 for the lowest point\n",
        "                df.at[highest_index, 'sell'] = 1\n",
        "                df.at[lowest_index, 'buy'] = 1\n",
        "\n",
        "        # Fill NaN values in 'buy' and 'sell' columns with 0\n",
        "        df['buy'].fillna(0, inplace=True)\n",
        "        df['sell'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Assuming df is your DataFrame\n",
        "        selected_cols = ['Date','Open','High','Low','Close','Volume','ema_50', 'ema_200', 'macd', 'rsi', 'stoch_oscillator', 'atr', 'obv', 'ichimoku_a','buy','sell']\n",
        "\n",
        "        # Create a copy of the DataFrame with only selected columns\n",
        "        df = df.loc[:, selected_cols].copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #update\n",
        "        self.df = df\n",
        "        return df\n",
        "\n",
        "    def monitor(self):\n",
        "        #df\n",
        "        df = self.df\n",
        "\n",
        "        #counts\n",
        "        total = len(df)\n",
        "        hold = ((df['buy'] == 0) & (df['sell'] == 0)).sum()\n",
        "        buy = ((df['buy'] == 1)).sum()\n",
        "        sell = ((df['sell'] == 1)).sum()\n",
        "\n",
        "        #percentages\n",
        "        buy_p = buy/total * 100\n",
        "        sell_p = sell/total * 100\n",
        "        hold_p = hold/total * 100\n",
        "\n",
        "        print(f\"\"\"\n",
        "              hold count : {hold}\n",
        "              buy count : {buy}\n",
        "              sell count : {sell}\n",
        "\n",
        "              hold percentage : {hold_p} %\n",
        "              buy percentage : {buy_p} %\n",
        "              sell percentage : {sell_p} %\n",
        "        \"\"\")\n",
        "\n",
        "        return buy_p , sell_p , hold_p\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "      #df\n",
        "      df = self.df\n",
        "\n",
        "\n",
        "      #train buy\n",
        "\n",
        "      # Separate rows where buy = 0 and buy = 1 into different DataFrames\n",
        "      df_buy_0 = df[df['buy'] == 0]\n",
        "      df_buy_1 = df[df['buy'] == 1]\n",
        "\n",
        "      # Determine the minimum count of buy = 0 and buy = 1\n",
        "      min_count = min(len(df_buy_0), len(df_buy_1))\n",
        "\n",
        "      # Sample randomly from each DataFrame to get the required number of rows\n",
        "      df_buy_0_sampled = df_buy_0.sample(n=min_count, random_state=42)\n",
        "      df_buy_1_sampled = df_buy_1.sample(n=min_count, random_state=42)\n",
        "\n",
        "      # Concatenate the sampled DataFrames to get the final balanced dataset\n",
        "      df_balanced = pd.concat([df_buy_0_sampled, df_buy_1_sampled])\n",
        "\n",
        "      # Shuffle the rows\n",
        "      df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "      # Prepare the data for training\n",
        "      X = df_balanced.drop(columns=['Date', 'buy', 'sell' , 'Close' ,'Open','High','Low','Volume'])  # Features\n",
        "      y = df_balanced['buy']  # Target variable\n",
        "\n",
        "\n",
        "\n",
        "      # Split the data into training and testing sets\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "      # Train the XGBoost classifier\n",
        "      model_buy = xgb.XGBClassifier()\n",
        "      model_buy.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "      #self\n",
        "      self.model_buy = model_buy\n",
        "\n",
        "      # Save the trained model to a file\n",
        "      with open('model_buy.pickle', 'wb') as f:\n",
        "          pickle.dump(model_buy, f)\n",
        "\n",
        "      # Load the saved model from file\n",
        "      with open('model_buy.pickle', 'rb') as f:\n",
        "          loaded_model_buy = pickle.load(f)\n",
        "\n",
        "      # Evaluate the model's performance\n",
        "      train_accuracy = loaded_model_buy.score(X_train, y_train)\n",
        "      test_accuracy = loaded_model_buy.score(X_test, y_test)\n",
        "\n",
        "      print(\"Training Accuracy(buy):\", train_accuracy)\n",
        "      print(\"Testing Accuracy:(buy)\", test_accuracy)\n",
        "\n",
        "\n",
        "      #df\n",
        "      df = self.df\n",
        "\n",
        "      # Separate rows where sell = 0 and sell = 1 into different DataFrames\n",
        "      df_sell_0 = df[df['sell'] == 0]\n",
        "      df_sell_1 = df[df['sell'] == 1]\n",
        "\n",
        "      # Determine the minimum count of sell = 0 and sell = 1\n",
        "      min_count = min(len(df_sell_0), len(df_sell_1))\n",
        "\n",
        "      # Sample randomly from each DataFrame to get the required number of rows\n",
        "      df_sell_0_sampled = df_sell_0.sample(n=min_count, random_state=42)\n",
        "      df_sell_1_sampled = df_sell_1.sample(n=min_count, random_state=42)\n",
        "\n",
        "      # Concatenate the sampled DataFrames to get the final balanced dataset\n",
        "      df_balanced_sell = pd.concat([df_sell_0_sampled, df_sell_1_sampled])\n",
        "\n",
        "      # Shuffle the rows\n",
        "      df_balanced_sell = df_balanced_sell.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "      # Prepare the data for training\n",
        "      X_sell = df_balanced_sell.drop(columns=['Date', 'buy', 'sell' , 'Close' ,'Open','High','Low','Volume'])  # Features\n",
        "      y_sell = df_balanced_sell['sell']  # Target variable\n",
        "\n",
        "\n",
        "\n",
        "      # Split the data into training and testing sets\n",
        "      X_train_sell, X_test_sell, y_train_sell, y_test_sell = train_test_split(X_sell, y_sell, test_size=0.2, random_state=42)\n",
        "\n",
        "      # Train the XGBoost classifier\n",
        "      model_sell = xgb.XGBClassifier()\n",
        "      model_sell.fit(X_train_sell, y_train_sell)\n",
        "\n",
        "      #self\n",
        "      self.model_sell = model_sell\n",
        "\n",
        "      # Save the trained model to a file\n",
        "      with open('model_sell.pickle', 'wb') as f:\n",
        "          pickle.dump(model_sell, f)\n",
        "\n",
        "      # Load the saved model from file\n",
        "      with open('model_sell.pickle', 'rb') as f:\n",
        "          loaded_model_sell = pickle.load(f)\n",
        "\n",
        "      # Evaluate the model's performance\n",
        "      train_accuracy_sell = loaded_model_sell.score(X_train_sell, y_train_sell)\n",
        "      test_accuracy_sell = loaded_model_sell.score(X_test_sell, y_test_sell)\n",
        "\n",
        "      print(\"Training Accuracy (Sell):\", train_accuracy_sell)\n",
        "      print(\"Testing Accuracy (Sell):\", test_accuracy_sell)\n",
        "\n",
        "\n",
        "\n",
        "    def load_models(self,model_buy,model_sell):\n",
        "        # Load the saved model from file\n",
        "        with open(model_buy, 'rb') as f:\n",
        "            loaded_model_buy = pickle.load(f)\n",
        "\n",
        "        with open(model_sell, 'rb') as f:\n",
        "            loaded_model_sell = pickle.load(f)\n",
        "\n",
        "\n",
        "        self.model_buy = loaded_model_buy\n",
        "        self.model_sell = loaded_model_sell\n",
        "\n",
        "\n",
        "\n",
        "    def get_signal(self,df):\n",
        "        # Use the loaded model to make prediction for the single record\n",
        "        prediction_sell = self.model_sell.predict(df)\n",
        "        prediction_sell = prediction_sell[0]\n",
        "\n",
        "        prediction_buy = self.model_buy.predict(df)\n",
        "        prediction_buy = prediction_buy[0]\n",
        "\n",
        "        if prediction_buy == 1 and prediction_sell == 0 :\n",
        "          return \"buy\"\n",
        "        elif prediction_buy == 0 and prediction_sell == 1 :\n",
        "          return \"sell\"\n",
        "        else :\n",
        "          return \"hold\"\n",
        "\n",
        "\n",
        "    def save_instance(instance, file_name):\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(instance, f)\n",
        "\n",
        "    def load_instance(file_name):\n",
        "        with open(file_name, 'rb') as f:\n",
        "            instance = pickle.load(f)\n",
        "        return instance\n",
        "\n",
        "\n",
        "    def plot (self):\n",
        "        df = self.df\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "        # Create traces for close prices, buy points, and sell points\n",
        "        trace_close = go.Scatter(x=df['Date'], y=df['Close'], mode='lines', name='Close')\n",
        "        trace_buy = go.Scatter(x=df[df['buy'] == 1]['Date'], y=df[df['buy'] == 1]['Close'], mode='markers', marker=dict(color='green'), name='Buy')\n",
        "        trace_sell = go.Scatter(x=df[df['sell'] == 1]['Date'], y=df[df['sell'] == 1]['Close'], mode='markers', marker=dict(color='red'), name='Sell')\n",
        "\n",
        "        # Create figure object\n",
        "        fig = go.Figure()\n",
        "\n",
        "        # Add traces to the figure\n",
        "        fig.add_trace(trace_close)\n",
        "        fig.add_trace(trace_buy)\n",
        "        fig.add_trace(trace_sell)\n",
        "\n",
        "        # Update layout\n",
        "        fig.update_layout(\n",
        "            title='Close Price with Buy and Sell Points',\n",
        "            xaxis=dict(title='Date'),\n",
        "            yaxis=dict(title='Close Price'),\n",
        "            showlegend=True\n",
        "        )\n",
        "\n",
        "        # Show plot\n",
        "        fig.show()\n"
      ],
      "metadata": {
        "id": "q0GfnsEh5F51"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#documentation\n",
        "\n"
      ],
      "metadata": {
        "id": "sEY7pw06z1eJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data\n",
        "file1 = \"Binance_SOLUSDT_d.csv\"\n",
        "file2 = \"SOLUSDT1.csv\"\n",
        "#-----------------------------\n",
        "\n",
        "#to choose the minimum profit between valid buy and sell points\n",
        "threshold = 0.6\n",
        "\n",
        "#to choose the window in which the trade happened\n",
        "window = 20\n",
        "\n",
        "#to create the object instance\n",
        "instance = Dataset(file1, threshold, window )"
      ],
      "metadata": {
        "id": "bGNP-IcQz5VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to create the valid buy and sell points\n",
        "df = instance.signal_setting()"
      ],
      "metadata": {
        "id": "bkxEFZ_RnkPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to save the data frame with features and points\n",
        "df.to_csv(\"df.csv\")"
      ],
      "metadata": {
        "id": "1-8rziYinhql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to plot the choosen buy and sell points\n",
        "instance.plot()"
      ],
      "metadata": {
        "id": "Kf-kqWW-nf5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to print the states (number of buy / sell points)\n",
        "instance.monitor()"
      ],
      "metadata": {
        "id": "ajxFSVwJneFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to train the buy and sell models on the created dataset\n",
        "instance.train()"
      ],
      "metadata": {
        "id": "UbuLAJFK9anz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#demo of using the models to get signals\n",
        "\n",
        "#features\n",
        "single_record = {\n",
        "    'ema_50': 19.502773,\n",
        "    'ema_200': 19.545588,\n",
        "    'macd': -0.007156,\n",
        "    'rsi': 53.699608,\n",
        "    'stoch_oscillator': 75.2345,\n",
        "    'atr': 1.5,\n",
        "    'obv': 10000,\n",
        "    'ichimoku_a': 20.5,\n",
        "\n",
        "                }\n",
        "\n",
        "# Convert the single record into a DataFrame\n",
        "df_single = pd.DataFrame([single_record])\n",
        "\n",
        "#to get signals\n",
        "signal = instance.get_signal(df_single)\n",
        "print(signal)\n",
        "\n"
      ],
      "metadata": {
        "id": "t6v2OGcuKQr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#backtest"
      ],
      "metadata": {
        "id": "uAMlaQvczzAB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOup1JGbp2PW"
      },
      "outputs": [],
      "source": [
        "#data\n",
        "data_test = file1\n",
        "df = pd.read_csv(data_test)\n",
        "#-------------------------\n",
        "\n",
        "#adding feature to the dataset records\n",
        "\n",
        "# Calculate EMA 50 and EMA 200\n",
        "df['ema_50'] = ta.trend.ema_indicator(close=df['Close'], window=50)\n",
        "df['ema_200'] = ta.trend.ema_indicator(close=df['Close'], window=200)\n",
        "\n",
        "# Calculate MACD\n",
        "df['macd'] = ta.trend.macd_diff(close=df['Close'])\n",
        "\n",
        "# Calculate RSI\n",
        "df['rsi'] = ta.momentum.rsi(close=df['Close'], window=14)\n",
        "\n",
        "# Calculate Stochastic Oscillator\n",
        "df['stoch_oscillator'] = ta.momentum.stoch(close=df['Close'], high=df[\"High\"] , low=df[\"Low\"])\n",
        "\n",
        "# Calculate Average True Range (ATR)\n",
        "df['atr'] = ta.volatility.average_true_range(high=df['High'], low=df['Low'], close=df['Close'])\n",
        "\n",
        "# Calculate On-Balance Volume (OBV)\n",
        "df['obv'] = ta.volume.on_balance_volume(close=df['Close'], volume=df['Volume'])\n",
        "\n",
        "# Calculate Ichimoku Cloud\n",
        "df['ichimoku_a'] = ta.trend.ichimoku_a(high=df['High'], low=df['Low'])\n",
        "\n",
        "# Drop rows with NaN values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#backtest class\n",
        "class str(Strategy):\n",
        "    def init(self):\n",
        "        pass\n",
        "\n",
        "    def next(self):\n",
        "\n",
        "        # Get current record features\n",
        "        current_df = {\n",
        "          'ema_50': self.data.ema_50[-1],\n",
        "          'ema_200': self.data.ema_200[-1],\n",
        "          'macd': self.data.macd[-1],\n",
        "          'rsi': self.data.rsi[-1],\n",
        "          'stoch_oscillator': self.data.stoch_oscillator[-1],\n",
        "          'atr': self.data.atr[-1],\n",
        "          'obv': self.data.obv[-1],\n",
        "          'ichimoku_a': self.data.ichimoku_a[-1]\n",
        "\n",
        "                      }\n",
        "\n",
        "        # Convert current_df into a DataFrame\n",
        "        df_single = pd.DataFrame([current_df])\n",
        "\n",
        "        # Use df_single to get signals\n",
        "        signal = instance.get_signal(df_single)\n",
        "\n",
        "        # Execute trades based on the signal\n",
        "        if \"buy\" in signal :\n",
        "            self.buy()\n",
        "\n",
        "        elif \"sell\" in signal :\n",
        "            self.position.close()\n",
        "\n",
        "#run backtest\n",
        "bt = Backtest(df, str,\n",
        "              cash=1000, commission=0.0,\n",
        "              exclusive_orders=False)\n",
        "\n",
        "output = bt.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print backtest results\n",
        "print(output)"
      ],
      "metadata": {
        "id": "EQpJW5SRfcNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot buy and sell points\n",
        "bt.plot()"
      ],
      "metadata": {
        "id": "CG1no7q3fUmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}